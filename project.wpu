#!wing
#!version=7.0
##################################################################
# Wing project file : User-specific branch                       #
##################################################################
[user attributes]
debug.err-values = {loc('../../../../Applications/WingPro.app/Contents/Resources/src/testing/runners/run_pytest_xml.py'): {}}
debug.exceptions-ignored = {loc('../../opt/miniconda3/envs/DeepForest/lib/python3.7/site-packages/_pytest/config/__init__.py'): {1514: True},
                            loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/config/__init__.py'): {1514: True}}
guimgr.overall-gui-state = {'windowing-policy': 'combined-window',
                            'windows': [{'name': 'BeCfPquEZeqQ6pfJCERhTaNA7C'\
        'a3fCTw',
        'size-state': 'maximized',
        'type': 'dock',
        'view': {'area': 'tall',
                 'constraint': None,
                 'current_pages': [0,
                                   0],
                 'full-screen': False,
                 'notebook_display': 'normal',
                 'notebook_percent': 0.19887955182072825,
                 'override_title': None,
                 'pagelist': [('project',
                               'tall',
                               0,
                               {'tree-state': {'file-sort-method': 'by name',
        'list-files-first': False,
        'tree-states': {'deep': {'expanded-nodes': [(1,),
        (1,
         0),
        (4,),
        (6,)],
                                 'selected-nodes': [],
                                 'top-node': (3,)}},
        'tree-style': 'deep'}}),
                              ('browser',
                               'tall',
                               0,
                               {}),
                              ('snippets',
                               'tall',
                               0,
                               {}),
                              ('source-assistant',
                               'tall',
                               2,
                               {}),
                              ('debug-stack',
                               'tall',
                               1,
                               {}),
                              ('indent',
                               'tall',
                               2,
                               {})],
                 'primary_view_state': {'area': 'wide',
        'constraint': None,
        'current_pages': [4,
                          2],
        'notebook_display': 'normal',
        'notebook_percent': 0.5665961945031712,
        'override_title': None,
        'pagelist': [('batch-search',
                      'wide',
                      0,
                      {'fScope': {'fFileSetName': 'All Source Files',
                                  'fLocation': None,
                                  'fRecursive': True,
                                  'fType': 'project-files'},
                       'fSearchSpec': {'fEndPos': None,
                                       'fIncludeLinenos': True,
                                       'fInterpretBackslashes': False,
                                       'fMatchCase': False,
                                       'fOmitBinary': True,
                                       'fRegexFlags': 42,
                                       'fReplaceText': '',
                                       'fReverse': False,
                                       'fSearchText': '',
                                       'fStartPos': 0,
                                       'fStyle': 'text',
                                       'fWholeWords': False,
                                       'fWrap': True},
                       'fUIOptions': {'fAutoBackground': True,
                                      'fFilePrefix': 'short-file',
                                      'fFindAfterReplace': True,
                                      'fInSelection': False,
                                      'fIncremental': True,
                                      'fReplaceOnDisk': False,
                                      'fShowFirstMatch': False,
                                      'fShowLineno': True,
                                      'fShowReplaceWidgets': False},
                       'replace-entry-expanded': False,
                       'search-entry-expanded': False}),
                     ('interactive-search',
                      'wide',
                      0,
                      {'fScope': {'fFileSetName': 'All Source Files',
                                  'fLocation': None,
                                  'fRecursive': True,
                                  'fType': 'project-files'},
                       'fSearchSpec': {'fEndPos': None,
                                       'fIncludeLinenos': True,
                                       'fInterpretBackslashes': False,
                                       'fMatchCase': False,
                                       'fOmitBinary': True,
                                       'fRegexFlags': 42,
                                       'fReplaceText': u'png',
                                       'fReverse': False,
                                       'fSearchText': u'sys',
                                       'fStartPos': 0,
                                       'fStyle': 'text',
                                       'fWholeWords': False,
                                       'fWrap': True},
                       'fUIOptions': {'fAutoBackground': True,
                                      'fFilePrefix': 'short-file',
                                      'fFindAfterReplace': True,
                                      'fInSelection': False,
                                      'fIncremental': True,
                                      'fReplaceOnDisk': False,
                                      'fShowFirstMatch': False,
                                      'fShowLineno': True,
                                      'fShowReplaceWidgets': False}}),
                     ('debug-data',
                      'wide',
                      0,
                      {}),
                     ('debug-breakpoints',
                      'wide',
                      0,
                      {'tree-state': []}),
                     ('testing',
                      'wide',
                      0,
                      {'added-files': [],
                       'filter': u'',
                       'recent-filters': None,
                       'sort-order': 'source-lineno',
                       'tree-state': {'expanded-nodes': [(1,),
        (2,),
        (2,
         0),
        (3,),
        (3,
         2),
        (3,
         2,
         1),
        (4,),
        (6,)],
                                      'selected-nodes': [(3,
        2)],
                                      'top-node': (0,)}}),
                     ('debug-io',
                      'wide',
                      1,
                      {}),
                     ('debug-exceptions',
                      'wide',
                      1,
                      {}),
                     ('debug-probe',
                      'wide',
                      2,
                      {'active-range': (None,
        -1,
        -1),
                       'attrib-starts': [],
                       'code-line': 'np.random.rand',
                       'first-line': 153L,
                       'folded-linenos': [],
                       'history': {u'file:/Applications/WingPro.app/Contents/Resources/src/testing/runners/run_pytest_xml.py': ['l'\
        'en(prediction)\n',
        'prediction[0]\n',
        'import pandas as pd\n',
        'pd.DataFrame(prediction[0]["boxes"])\n',
        'prediction[0]["boxes"].numpy()\n',
        'prediction[0]["boxes"].cpu()\n',
        'prediction[0]["boxes"].cpu().numpy()\n',
        'pd.DataFrame(prediction[0]["boxes"].cpu().detach().numpy())\n',
        'pd.DataFrame(image["boxes"].cpu().detach().numpy(),names=["xmin","y'\
        'min","xmax","ymax"])\n',
        'pd.DataFrame(image["boxes"].cpu().detach().numpy(),columns=["xmin",'\
        '"ymin","xmax","ymax"])\n',
        ' pd.DataFrame(image["boxes"].cpu().detach().numpy())\n',
        'pd.DataFrame(image["boxes"].cpu().detach().numpy())\n',
        'image["boxes"].cpu().detach().numpy()\n',
        'image["boxes"]\n',
        'prediction[0]["boxes"].cpu().detach().numpy()\n',
        'prediction.cpu.detach()\n',
        'path\n',
        'import numpy as no\n',
        'isinstance(image,np.array)\n',
        'not isinstance(image,str)\n',
        'prediction = self.backbone(image)\n',
        'prediction\n',
        'prediction[0]["boxes"]\n',
        'prediction[0]["boxes"].shape\n',
        'prediction[0]["boxes"].shape[-0]\n',
        'len(prediction[0]["boxes"])\n',
        'np.\n',
        'np.random\n',
        'import numpy as np\n']},
                       'launch-id': None,
                       'sel-line': 175L,
                       'sel-line-start': 7118L,
                       'selection_end': 7132L,
                       'selection_start': 7132L,
                       'zoom': 0L}),
                     ('debug-watch',
                      'wide',
                      1,
                      {'node-states': [],
                       'tree-state': {'expanded-nodes': [],
                                      'selected-nodes': [],
                                      'top-node': (0,)}}),
                     ('debug-modules',
                      'wide',
                      1,
                      {}),
                     ('python-shell',
                      'wide',
                      2,
                      {'active-range': (None,
        -1,
        -1),
                       'attrib-starts': [],
                       'code-line': '',
                       'first-line': 0L,
                       'folded-linenos': [],
                       'history': {},
                       'launch-id': None,
                       'sel-line': 3L,
                       'sel-line-start': 162L,
                       'selection_end': 162L,
                       'selection_start': 162L,
                       'zoom': 0L}),
                     ('bookmarks',
                      'wide',
                      1,
                      {}),
                     ('messages',
                      'wide',
                      2,
                      {}),
                     ('os-command',
                      'wide',
                      1,
                      {})],
        'primary_view_state': {'editor_states': ({'bookmarks': ([[loc('deepforest/main.py'),
        {'attrib-starts': [('deepforest|0|',
                            13),
                           ('deepforest|0|.predict_image|0|',
                            55)],
         'code-line': '\n',
         'first-line': 54L,
         'folded-linenos': [],
         'sel-line': 70L,
         'sel-line-start': 2789L,
         'selection_end': 2789L,
         'selection_start': 2789L,
         'zoom': 0L},
        1610045819.477232],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_fromarray|0|',
                             52)],
          'code-line': '    \n',
          'first-line': 43L,
          'folded-linenos': [],
          'sel-line': 56L,
          'sel-line-start': 1571L,
          'selection_end': 1575L,
          'selection_start': 1575L,
          'zoom': 0L},
         1610045819.485874],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_fromarray|0|',
                             52)],
          'code-line': '\n',
          'first-line': 50L,
          'folded-linenos': [],
          'sel-line': 59L,
          'sel-line-start': 1709L,
          'selection_end': 1709L,
          'selection_start': 1709L,
          'zoom': 0L},
         1610045854.091397],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             13),
                            ('deepforest|0|.predict_image|0|',
                             55)],
          'code-line': '\n',
          'first-line': 54L,
          'folded-linenos': [],
          'sel-line': 70L,
          'sel-line-start': 2789L,
          'selection_end': 2789L,
          'selection_start': 2789L,
          'zoom': 0L},
         1610045854.102538],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             13),
                            ('deepforest|0|.predict_image|0|',
                             55)],
          'code-line': '            raise ValueError("Path expects a string '\
                       'path to image on disk")\n',
          'first-line': 60L,
          'folded-linenos': [],
          'sel-line': 69L,
          'sel-line-start': 2713L,
          'selection_end': 2788L,
          'selection_start': 2713L,
          'zoom': 0L},
         1610045858.289766],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_fromarray|0|',
                             52)],
          'code-line': '\n',
          'first-line': 50L,
          'folded-linenos': [],
          'sel-line': 59L,
          'sel-line-start': 1709L,
          'selection_end': 1709L,
          'selection_start': 1709L,
          'zoom': 0L},
         1610045858.293467],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_fromarray|0|',
                             52)],
          'code-line': 'def test_predict_image_fromarray(trained_model):\n',
          'first-line': 43L,
          'folded-linenos': [],
          'sel-line': 52L,
          'sel-line-start': 1361L,
          'selection_end': 1409L,
          'selection_start': 1361L,
          'zoom': 0L},
         1610045863.975685],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             13),
                            ('deepforest|0|.predict_tile|0|',
                             92)],
          'code-line': '        Args:\n',
          'first-line': 59L,
          'folded-linenos': [],
          'sel-line': 102L,
          'sel-line-start': 3936L,
          'selection_end': 3949L,
          'selection_start': 3949L,
          'zoom': 0L},
         1610045913.011168],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_fromarray|0|',
                             52)],
          'code-line': 'def test_predict_image_fromarray(trained_model):\n',
          'first-line': 43L,
          'folded-linenos': [],
          'sel-line': 52L,
          'sel-line-start': 1361L,
          'selection_end': 1409L,
          'selection_start': 1361L,
          'zoom': 0L},
         1610045913.022421],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': 'def test_predict_image_empty(m):\n',
          'first-line': 31L,
          'folded-linenos': [],
          'sel-line': 40L,
          'sel-line-start': 850L,
          'selection_end': 882L,
          'selection_start': 850L,
          'zoom': 0L},
         1610045918.494786],
        [loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/fixtures.py'),
         {'attrib-starts': [('FixtureFunctionMarker|0|',
                             1186),
                            ('FixtureFunctionMarker|0|.__call__|0|',
                             1200)],
          'code-line': '            raise ValueError(\n',
          'first-line': 1196L,
          'folded-linenos': [],
          'sel-line': 1205L,
          'sel-line-start': 47445L,
          'selection_end': 47474L,
          'selection_start': 47445L,
          'zoom': 0L},
         1610045921.629313],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': 'def test_predict_image_empty(m):\n',
          'first-line': 31L,
          'folded-linenos': [],
          'sel-line': 40L,
          'sel-line-start': 850L,
          'selection_end': 882L,
          'selection_start': 850L,
          'zoom': 0L},
         1610045921.632035],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             13),
                            ('deepforest|0|.predict_image|0|',
                             55)],
          'code-line': '            return None\n',
          'first-line': 65L,
          'folded-linenos': [],
          'sel-line': 80L,
          'sel-line-start': 3096L,
          'selection_end': 3116L,
          'selection_start': 3116L,
          'zoom': 0L},
         1610045992.842401],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': 'def test_predict_image_empty(m):\n',
          'first-line': 31L,
          'folded-linenos': [],
          'sel-line': 40L,
          'sel-line-start': 850L,
          'selection_end': 882L,
          'selection_start': 850L,
          'zoom': 0L},
         1610045992.854123],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_fromfile|0|',
                             45)],
          'code-line': '    path = get_data(path="2019_YELL_2_528000_4978000'\
                       '_image_crop2.png")\n',
          'first-line': 40L,
          'folded-linenos': [],
          'sel-line': 46L,
          'sel-line-start': 1083L,
          'selection_end': 1123L,
          'selection_start': 1123L,
          'zoom': 0L},
         1610046018.346593],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': '    path = get_data(path="2019_YELL_2_528000_4978000'\
                       '_image_crop2.png")\n',
          'first-line': 28L,
          'folded-linenos': [],
          'sel-line': 41L,
          'sel-line-start': 883L,
          'selection_end': 922L,
          'selection_start': 922L,
          'zoom': 0L},
         1610046036.575208],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': '    assert prediction is None\n',
          'first-line': 34L,
          'folded-linenos': [],
          'sel-line': 43L,
          'sel-line-start': 1000L,
          'selection_end': 1029L,
          'selection_start': 1000L,
          'zoom': 0L},
         1610046038.841977],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             13),
                            ('deepforest|0|.predict_image|0|',
                             55)],
          'code-line': '        #return None for no predictions\n',
          'first-line': 66L,
          'folded-linenos': [],
          'sel-line': 78L,
          'sel-line-start': 3013L,
          'selection_end': 3024L,
          'selection_start': 3024L,
          'zoom': 0L},
         1610046086.309968],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': '    assert prediction is None\n',
          'first-line': 34L,
          'folded-linenos': [],
          'sel-line': 43L,
          'sel-line-start': 1000L,
          'selection_end': 1029L,
          'selection_start': 1000L,
          'zoom': 0L},
         1610046086.320479],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_predict_image_empty|0|',
                             40)],
          'code-line': 'def test_predict_image_empty(m):\n',
          'first-line': 31L,
          'folded-linenos': [],
          'sel-line': 40L,
          'sel-line-start': 850L,
          'selection_end': 882L,
          'selection_start': 850L,
          'zoom': 0L},
         1610046086.881264]],
        20),
        'current-loc': loc('tests/test_main.py'),
        'editor-state-list': [(loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/fixtures.py'),
                               {'attrib-starts': [('FixtureFunctionMarker|0|',
        1186),
        ('FixtureFunctionMarker|0|.__call__|0|',
         1200)],
                                'code-line': '            raise ValueError('\
        '\n',
                                'first-line': 1196L,
                                'folded-linenos': [],
                                'sel-line': 1205L,
                                'sel-line-start': 47445L,
                                'selection_end': 47474L,
                                'selection_start': 47445L,
                                'zoom': 0L}),
                              (loc('deepforest/main.py'),
                               {'attrib-starts': [('deepforest|0|',
        13),
        ('deepforest|0|.predict_image|0|',
         55)],
                                'code-line': '        #return None for no pr'\
        'edictions\n',
                                'first-line': 66L,
                                'folded-linenos': [],
                                'sel-line': 78L,
                                'sel-line-start': 3013L,
                                'selection_end': 3024L,
                                'selection_start': 3024L,
                                'zoom': 0L}),
                              (loc('deepforest/preprocess.py'),
                               {'attrib-starts': [],
                                'code-line': '\n',
                                'first-line': 19L,
                                'folded-linenos': [],
                                'sel-line': 13L,
                                'sel-line-start': 298L,
                                'selection_end': 298L,
                                'selection_start': 298L,
                                'zoom': 0L}),
                              (loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/retinanet.py'),
                               {'attrib-starts': [('RetinaNet|0|',
        243),
        ('RetinaNet|0|.forward|0|',
         483)],
                                'code-line': '        for img in images:\n',
                                'first-line': 492L,
                                'folded-linenos': [],
                                'sel-line': 515L,
                                'sel-line-start': 22606L,
                                'selection_end': 22606L,
                                'selection_start': 22606L,
                                'zoom': 0L}),
                              (loc('tests/test_main.py'),
                               {'attrib-starts': [('test_predict_image_empty'\
        '|0|',
        40)],
                                'code-line': '    image = np.random.random(('\
        '400,400,3))\n',
                                'first-line': 31L,
                                'folded-linenos': [],
                                'sel-line': 41L,
                                'sel-line-start': 883L,
                                'selection_end': 911L,
                                'selection_start': 911L,
                                'zoom': 0L}),
                              (loc('deepforest/training.py'),
                               {'attrib-starts': [('train_one_epoch|0|',
        8)],
                                'code-line': '    metric_logger = utils.Metr'\
        'icLogger(delimiter="  ")\n',
                                'first-line': 3L,
                                'folded-linenos': [],
                                'sel-line': 10L,
                                'sel-line-start': 313L,
                                'selection_end': 367L,
                                'selection_start': 367L,
                                'zoom': 0L}),
                              (loc('deepforest/training_utils.py'),
                               {'attrib-starts': [],
                                'code-line': 'from collections import defaul'\
        'tdict, deque\n',
                                'first-line': 105L,
                                'folded-linenos': [],
                                'sel-line': 0L,
                                'sel-line-start': 0L,
                                'selection_end': 0L,
                                'selection_start': 0L,
                                'zoom': 0L}),
                              (loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/transform.py'),
                               {'attrib-starts': [('GeneralizedRCNNTransform'\
        '|0|',
        57),
        ('GeneralizedRCNNTransform|0|.normalize|0|',
         119)],
                                'code-line': '    def normalize(self, image)'\
        ':\n',
                                'first-line': 108L,
                                'folded-linenos': [],
                                'sel-line': 119L,
                                'sel-line-start': 4685L,
                                'selection_end': 4716L,
                                'selection_start': 4716L,
                                'zoom': 0L}),
                              (loc('deepforest/visualize.py'),
                               {'attrib-starts': [],
                                'code-line': '\n',
                                'first-line': 1L,
                                'folded-linenos': [],
                                'sel-line': 4L,
                                'sel-line-start': 145L,
                                'selection_end': 145L,
                                'selection_start': 145L,
                                'zoom': 0L})],
        'has-focus': False,
        'locked': False},
        [loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/fixtures.py'),
         loc('deepforest/main.py'),
         loc('deepforest/preprocess.py'),
         loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/retinanet.py'),
         loc('tests/test_main.py'),
         loc('deepforest/training.py'),
         loc('deepforest/training_utils.py'),
         loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/transform.py'),
         loc('deepforest/visualize.py')]),
                               'open_files': [u'deepforest/training_utils.py',
        u'deepforest/training.py',
        u'../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/retinanet.py',
        u'deepforest/preprocess.py',
        u'deepforest/visualize.py',
        u'../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/transform.py',
        u'deepforest/main.py',
        u'tests/test_main.py']},
        'saved_notebook_display': None,
        'split_percents': {0: 0.4044943820224719},
        'splits': 2,
        'tab_location': 'top',
        'traversal_pos': ((1,
                           2),
                          1610046052.732872),
        'user_data': {}},
                 'saved_notebook_display': None,
                 'split_percents': {0: 0.5},
                 'splits': 2,
                 'tab_location': 'left',
                 'traversal_pos': ((0,
                                    0),
                                   1607965912.374172),
                 'user_data': {}},
        'window-alloc': (1608,
                         23,
                         1709,
                         1057)}]}
guimgr.recent-documents = [loc('tests/test_main.py'),
                           loc('deepforest/main.py'),
                           loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/fixtures.py'),
                           loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/transform.py'),
                           loc('deepforest/visualize.py'),
                           loc('deepforest/preprocess.py'),
                           loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/retinanet.py'),
                           loc('deepforest/training.py'),
                           loc('deepforest/training_utils.py')]
guimgr.visual-state = {loc('../../../../Applications/WingPro.app/Contents/Resources/src/testing/runners/run_pytest_xml.py'): {'a'\
        'ttrib-starts': [('RunInSingleDir|0|',
                          456)],
        'code-line': '        import pytest\n',
        'first-line': 454L,
        'folded-linenos': [],
        'sel-line': 466L,
        'sel-line-start': 16384L,
        'selection_end': 16405L,
        'selection_start': 16384L,
        'zoom': 0L},
                       loc('.travis.yml'): {'attrib-starts': [],
        'code-line': 'env: TRAVIS=true\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 460L,
        'selection_end': 476L,
        'selection_start': 476L,
        'zoom': 0L},
                       loc('azure-pipelines.yml'): {'attrib-starts': [],
        'code-line': '  - script: |\n',
        'first-line': 20L,
        'folded-linenos': [],
        'sel-line': 33L,
        'sel-line-start': 799L,
        'selection_end': 812L,
        'selection_start': 812L,
        'zoom': 0L},
                       loc('deepforest/data/2019_YELL_2_528000_4978000_image_crop2.xml'): {'a'\
        'ttrib-starts': [],
        'code-line': '    <filename>2019_YELL_2_528000_4978000_image_crop2.p'\
                     'ng</filename>\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 39L,
        'selection_end': 95L,
        'selection_start': 95L,
        'zoom': 0L},
                       loc('deepforest/data/2019_YELL_2_541000_4977000_image_crop.tif'): {'a'\
        'ttrib-starts': [],
        'code-line': 'MM\0*\0\r',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/data/2019_YELL_2_541000_4977000_image_crop.xml'): {'a'\
        'ttrib-starts': [],
        'code-line': '    <filename>2019_YELL_2_541000_4977000_image_crop.pn'\
                     'g</filename>\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 39L,
        'selection_end': 94L,
        'selection_start': 94L,
        'zoom': 0L},
                       loc('deepforest/data/deepforest_config.yml'): {'attri'\
        'b-starts': [],
        'code-line': '### \n',
        'first-line': 26L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 1510L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/data/example.csv'): {'attrib-starts': [],
        'code-line': '2019_YELL_2_541000_4977000_image_crop.png,51,374,97,41'\
                     '6,Tree\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 19L,
        'sel-line-start': 1173L,
        'selection_end': 1220L,
        'selection_start': 1220L,
        'zoom': 0L},
                       loc('deepforest/dataset.py'): {'attrib-starts': [],
        'code-line': 'idx_to_label = {\n',
        'first-line': 19L,
        'folded-linenos': [],
        'sel-line': 27L,
        'sel-line-start': 882L,
        'selection_end': 914L,
        'selection_start': 882L,
        'zoom': 0L},
                       loc('deepforest/deepforest.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/engine.py'): {'attrib-starts': [],
        'code-line': 'from coco_eval import CocoEvaluator\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 256L,
        'selection_end': 291L,
        'selection_start': 291L,
        'zoom': 0L},
                       loc('deepforest/main.py'): {'attrib-starts': [('deepf'\
        'orest|0|',
        12),
        ('deepforest|0|.predict_image|0|',
         54)],
        'code-line': '        image = preprocess.preprocess_image(image)\n',
        'first-line': 38L,
        'folded-linenos': [],
        'sel-line': 57L,
        'sel-line-start': 1980L,
        'selection_end': 1988L,
        'selection_start': 1988L,
        'zoom': 0L},
                       loc('deepforest/model.py'): {'attrib-starts': [('crea'\
        'te_model|0|',
        13)],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 324L,
        'selection_end': 324L,
        'selection_start': 324L,
        'zoom': 0L},
                       loc('deepforest/preprocess.py'): {'attrib-starts': [('p'\
        'reprocess_image|0|',
        14)],
        'code-line': 'def preprocess_image(image):   \n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 14L,
        'sel-line-start': 299L,
        'selection_end': 319L,
        'selection_start': 303L,
        'zoom': 0L},
                       loc('deepforest/retinanet_train.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/train.py'): {'attrib-starts': [('trai'\
        'n|0|',
        2)],
        'code-line': '        config: a deepforest config object\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 226L,
        'selection_end': 268L,
        'selection_start': 268L,
        'zoom': 0L},
                       loc('deepforest/training.py'): {'attrib-starts': [('r'\
        'un|0|',
        52)],
        'code-line': '        data_loader_train = torch.utils.data.DataLoade'\
                     'r(\n',
        'first-line': 50L,
        'folded-linenos': [],
        'sel-line': 75L,
        'sel-line-start': 2682L,
        'selection_end': 2738L,
        'selection_start': 2738L,
        'zoom': 0L},
                       loc('deepforest/transforms.py'): {'attrib-starts': [('T'\
        'oTensor|0|',
        29),
        ('ToTensor|0|.__call__|0|',
         30)],
        'code-line': '        image = F.to_tensor(image).float()\n',
        'first-line': 13L,
        'folded-linenos': [],
        'sel-line': 31L,
        'sel-line-start': 904L,
        'selection_end': 945L,
        'selection_start': 945L,
        'zoom': 0L},
                       loc('deepforest/utilities.py'): {'attrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 138L,
        'selection_end': 153L,
        'selection_start': 153L,
        'zoom': 0L},
                       loc('deepforest_config.yml'): {'attrib-starts': [],
        'code-line': 'workers: 1\n',
        'first-line': 12L,
        'folded-linenos': [],
        'sel-line': 37L,
        'sel-line-start': 1293L,
        'selection_end': 1293L,
        'selection_start': 1293L,
        'zoom': 0L},
                       loc('environment.yml'): {'attrib-starts': [],
        'code-line': '  - scikit-image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 27L,
        'sel-line-start': 362L,
        'selection_end': 378L,
        'selection_start': 378L,
        'zoom': 0L},
                       loc('evaluate.py'): {'attrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 12L,
        'selection_start': 12L,
        'zoom': 0L},
                       loc('main.py'): {'attrib-starts': [('deepforest|0|',
        7),
        ('deepforest|0|.__init__|0|',
         10)],
        'code-line': '        # if not use installed.\n',
        'first-line': 120L,
        'folded-linenos': [],
        'sel-line': 12L,
        'sel-line-start': 413L,
        'selection_end': 444L,
        'selection_start': 444L,
        'zoom': 0L},
                       loc('requirements.txt'): {'attrib-starts': [],
        'code-line': 'numpy\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 12L,
        'sel-line-start': 98L,
        'selection_end': 103L,
        'selection_start': 103L,
        'zoom': 0L},
                       loc('setup.py'): {'attrib-starts': [],
        'code-line': '      install_requires=[\n',
        'first-line': 56L,
        'folded-linenos': [],
        'sel-line': 63L,
        'sel-line-start': 1840L,
        'selection_end': 1864L,
        'selection_start': 1864L,
        'zoom': 0L},
                       loc('tests/test_data.py'): {'attrib-starts': [],
        'code-line': '# test data locations and existance\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_dataset.py'): {'attrib-starts': [('te'\
        'st_TreeDataset|0|',
        7)],
        'code-line': '    assert image.max() <= 1\n',
        'first-line': 9L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 491L,
        'selection_end': 518L,
        'selection_start': 518L,
        'zoom': 0L},
                       loc('tests/test_deepforest.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_environment.py'): {'attrib-starts': [],
        'code-line': '#test environment\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 17L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_keras_retinanet.py'): {'attrib-starts': [],
        'code-line': '# test loading of keras retinanet\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 33L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_main.py'): {'attrib-starts': [('m|0|',
        10)],
        'code-line': '    return m\n',
        'first-line': 10L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 398L,
        'selection_end': 410L,
        'selection_start': 410L,
        'zoom': 0L},
                       loc('tests/test_model.py'): {'attrib-starts': [('test'\
        '_load_backbone|0|',
        5)],
        'code-line': '',
        'first-line': 1L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 230L,
        'selection_end': 230L,
        'selection_start': 230L,
        'zoom': 0L},
                       loc('tests/test_preprocess.py'): {'attrib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 4L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 97L,
        'selection_end': 118L,
        'selection_start': 118L,
        'zoom': 0L},
                       loc('tests/test_tfrecords.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_utilities.py'): {'attrib-starts': [('t'\
        'est_xml_to_annotations|0|',
        18)],
        'code-line': '    #release_tag, weights = utilities.use_release()\n',
        'first-line': 18L,
        'folded-linenos': [],
        'sel-line': 30L,
        'sel-line-start': 678L,
        'selection_end': 729L,
        'selection_start': 729L,
        'zoom': 0L},
                       loc('tests/test_visualize.py'): {'attrib-starts': [('m'\
        '|0|',
        9)],
        'code-line': '    m.load_dataset(csv_file=csv_file, root_dir=os.path'\
                     '.dirname(csv_file), train=True)\n',
        'first-line': 7L,
        'folded-linenos': [],
        'sel-line': 15L,
        'sel-line-start': 320L,
        'selection_end': 370L,
        'selection_start': 370L,
        'zoom': 0L},
                       loc('../DeepForest/deepforest/deepforest.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'from deepforest.retinanet_train import main as retinan'\
                     'et_train\n',
        'first-line': 20L,
        'folded-linenos': [],
        'sel-line': 26L,
        'sel-line-start': 631L,
        'selection_end': 662L,
        'selection_start': 662L,
        'zoom': 0L},
                       loc('../deepforest-feedstock/conda-forge.yml'): {'att'\
        'rib-starts': [],
        'code-line': 'conda_forge_output_validation: true\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../deepforest-feedstock/recipe/meta.yaml'): {'at'\
        'trib-starts': [],
        'code-line': '    - tensorflow ==1.14.0\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 48L,
        'sel-line-start': 962L,
        'selection_end': 987L,
        'selection_start': 987L,
        'zoom': 0L},
                       loc('../vision/references/classification/train.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 39L,
        'selection_end': 49L,
        'selection_start': 49L,
        'zoom': 0L},
                       loc('../vision/references/classification/train_quantization.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import copy\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 38L,
        'selection_end': 38L,
        'selection_start': 38L,
        'zoom': 0L},
                       loc('../vision/references/classification/utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 141L,
        'selection_end': 141L,
        'selection_start': 141L,
        'zoom': 0L},
                       loc('../vision/references/detection/coco_eval.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import json\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/detection/coco_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import copy\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/detection/engine.py'): {'at'\
        'trib-starts': [('_get_iou_types|0|',
                         57)],
        'code-line': '    if isinstance(model, torch.nn.parallel.Distributed'\
                     'DataParallel):\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 59L,
        'sel-line-start': 1810L,
        'selection_end': 1844L,
        'selection_start': 1841L,
        'zoom': 0L},
                       loc('../vision/references/detection/group_by_aspect_ratio.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import bisect\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/detection/train.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import torchvision\n',
        'first-line': 2L,
        'folded-linenos': [],
        'sel-line': 25L,
        'sel-line-start': 952L,
        'selection_end': 952L,
        'selection_start': 952L,
        'zoom': 0L},
                       loc('../vision/references/detection/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 1L,
        'sel-line-start': 14L,
        'selection_end': 14L,
        'selection_start': 14L,
        'zoom': 0L},
                       loc('../vision/references/detection/utils.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import errno\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 133L,
        'selection_end': 145L,
        'selection_start': 145L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/coco_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from pycocotools import mask as coco_mask\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 102L,
        'selection_end': 115L,
        'selection_start': 115L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/train.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch.utils.data\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 52L,
        'selection_end': 61L,
        'selection_start': 61L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import random\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 41L,
        'selection_end': 46L,
        'selection_start': 46L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import defaultdict, deque\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/similarity/loss.py'): {'att'\
        'rib-starts': [],
        'code-line': "'''\n",
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 128L,
        'selection_end': 131L,
        'selection_start': 131L,
        'zoom': 0L},
                       loc('../vision/references/similarity/model.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import torch.nn as nn\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/similarity/sampler.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 108L,
        'selection_end': 108L,
        'selection_start': 108L,
        'zoom': 0L},
                       loc('../vision/references/similarity/test.py'): {'att'\
        'rib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 179L,
        'selection_end': 179L,
        'selection_start': 179L,
        'zoom': 0L},
                       loc('../vision/references/similarity/train.py'): {'at'\
        'trib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 184L,
        'selection_end': 184L,
        'selection_start': 184L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/scheduler.py'): {'a'\
        'ttrib-starts': [('WarmupMultiStepLR|0|',
                          4)],
        'code-line': 'class WarmupMultiStepLR(torch.optim.lr_scheduler._LRSc'\
                     'heduler):\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 47L,
        'selection_end': 88L,
        'selection_start': 88L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/train.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torch.utils.data.dataloader import default_collat'\
                     'e\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 75L,
        'selection_end': 91L,
        'selection_start': 91L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import defaultdict, deque\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/caltech.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/celeba.py'): {'at'\
        'trib-starts': [],
        'code-line': 'from functools import partial\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/cifar.py'): {'att'\
        'rib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/cityscapes.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from typing import Any, Callable, Dict, List, Optional'\
                     ', Union, Tuple\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 57L,
        'selection_end': 57L,
        'selection_start': 57L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/coco.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'from .vision import VisionDataset\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/fakedata.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/flickr.py'): {'at'\
        'trib-starts': [],
        'code-line': 'from collections import defaultdict\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/folder.py'): {'at'\
        'trib-starts': [],
        'code-line': 'from .vision import VisionDataset\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/hmdb51.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import glob\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/imagenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import tempfile\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 78L,
        'selection_end': 93L,
        'selection_start': 93L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/kinetics.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from .utils import list_dir\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/lsun.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'import string\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 91L,
        'selection_end': 104L,
        'selection_start': 104L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/mnist.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 72L,
        'selection_end': 81L,
        'selection_start': 81L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/omniglot.py'): {'a'\
        'ttrib-starts': [('Omniglot|0|',
                          7)],
        'code-line': '            creates from the "evaluation" set. This te'\
                     'rminology is defined by the authors.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 13L,
        'sel-line-start': 537L,
        'selection_end': 601L,
        'selection_start': 601L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/phototour.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 115L,
        'selection_end': 127L,
        'selection_start': 127L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/places365.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/sbd.py'): {'attri'\
        'b-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/sbu.py'): {'attri'\
        'b-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/semeion.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/stl10.py'): {'att'\
        'rib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/svhn.py'): {'attr'\
        'ib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 215L,
        'selection_end': 215L,
        'selection_start': 215L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/ucf101.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/usps.py'): {'attr'\
        'ib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 175L,
        'selection_end': 175L,
        'selection_start': 175L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/utils.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import tarfile\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 52L,
        'selection_end': 52L,
        'selection_start': 52L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/video_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '    _read_video_from_file,\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 9L,
        'sel-line-start': 168L,
        'selection_end': 194L,
        'selection_start': 194L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/vision.py'): {'at'\
        'trib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 112L,
        'selection_end': 112L,
        'selection_start': 112L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/voc.py'): {'attri'\
        'b-starts': [],
        'code-line': 'from .utils import download_url, verify_str_arg\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 197L,
        'selection_end': 228L,
        'selection_start': 228L,
        'zoom': 0L},
                       loc('../vision/torchvision/io/image.py'): {'attrib-st'\
        'arts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 73L,
        'selection_end': 73L,
        'selection_start': 73L,
        'zoom': 0L},
                       loc('../vision/torchvision/io/video.py'): {'attrib-st'\
        'arts': [],
        'code-line': '        av = ImportError(\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 329L,
        'selection_end': 354L,
        'selection_start': 354L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/alexnet.py'): {'att'\
        'rib-starts': [],
        'code-line': 'model_urls = {\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 9L,
        'sel-line-start': 139L,
        'selection_end': 153L,
        'selection_start': 153L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/densenet.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import re\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/anchor_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '# Copyright (c) Facebook, Inc. and its affiliates. All'\
                     ' Rights Reserved.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/backbone_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/faster_rcnn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch.nn.functional as F\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 71L,
        'selection_end': 102L,
        'selection_start': 102L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/generalized_rcnn.py'): {'a'\
        'ttrib-starts': [('GeneralizedRCNN|0|',
                          12),
                         ('GeneralizedRCNN|0|.eager_outputs|0|',
                          35)],
        'code-line': '        # type: (Dict[str, Tensor], List[Dict[str, Ten'\
                     'sor]]) -> Union[Dict[str, Tensor], List[Dict[str, Tens'\
                     'or]]]\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 36L,
        'sel-line-start': 1056L,
        'selection_end': 1113L,
        'selection_start': 1107L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/image_list.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '# Copyright (c) Facebook, Inc. and its affiliates. All'\
                     ' Rights Reserved.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/keypoint_rcnn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torchvision.ops import MultiScaleRoIAlign\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 35L,
        'selection_end': 81L,
        'selection_start': 81L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/mask_rcnn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 2L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 266L,
        'selection_end': 266L,
        'selection_start': 266L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/retinanet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from typing import Dict, List, Tuple, Optional\n',
        'first-line': 3L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 107L,
        'selection_end': 153L,
        'selection_start': 145L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/roi_heads.py'): {'a'\
        'ttrib-starts': [('RoIHeads|0|',
                          484),
                         ('RoIHeads|0|.check_targets|0|',
                          619)],
        'code-line': '        # type: (Optional[List[Dict[str, Tensor]]]) ->'\
                     ' None\n',
        'first-line': 607L,
        'folded-linenos': [],
        'sel-line': 620L,
        'sel-line-start': 22884L,
        'selection_end': 22909L,
        'selection_start': 22901L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/rpn.py'): {'a'\
        'ttrib-starts': [('RegionProposalNetwork|0|',
                          103),
                         ('RegionProposalNetwork|0|.pre_nms_top_n|0|',
                          167)],
        'code-line': '    def pre_nms_top_n(self):\n',
        'first-line': 157L,
        'folded-linenos': [],
        'sel-line': 167L,
        'sel-line-start': 6362L,
        'selection_end': 6379L,
        'selection_start': 6379L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/transform.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 157L,
        'selection_end': 157L,
        'selection_start': 157L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/googlenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/inception.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import namedtuple\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/mnasnet.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/mobilenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 90L,
        'selection_end': 90L,
        'selection_start': 90L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/mobilenetv2.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torch import nn\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/resnet.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/segmentation/deeplabv3.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/segmentation/fcn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torch import nn\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/segmentation/segmentation.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 279L,
        'selection_end': 279L,
        'selection_start': 279L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/shufflenetv2.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/squeezenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/utils.py'): {'attri'\
        'b-starts': [],
        'code-line': 'try:\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/vgg.py'): {'attrib-'\
        'starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/video/resnet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from ..utils import load_state_dict_from_url\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 23L,
        'selection_end': 69L,
        'selection_start': 31L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/_box_convert.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/_register_onnx_ops.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import sys\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/_utils.py'): {'attrib-'\
        'starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/boxes.py'): {'attrib-s'\
        'tarts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/deform_conv.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import math\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/feature_pyramid_network.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import OrderedDict\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/focal_loss.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/misc.py'): {'attrib-st'\
        'arts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 14L,
        'sel-line-start': 328L,
        'selection_end': 328L,
        'selection_start': 328L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/poolers.py'): {'attrib'\
        '-starts': [],
        'code-line': '# Copyright (c) Facebook, Inc. and its affiliates. All'\
                     ' Rights Reserved.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/ps_roi_align.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/ps_roi_pool.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/roi_align.py'): {'attr'\
        'ib-starts': [('roi_align|0|',
                       10)],
        'code-line': 'def roi_align(\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 260L,
        'selection_end': 274L,
        'selection_start': 274L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/roi_pool.py'): {'attri'\
        'b-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/autoaugment.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import math\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/functional.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import math\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/functional_pil.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import numbers\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/functional_tensor.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from .functional import InterpolationMode, _interpolat'\
                     'ion_modes_from_int\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 271L,
        'selection_end': 312L,
        'selection_start': 295L,
        'zoom': 0L},
                       loc('../../Downloads/tv-training-code.py'): {'attrib-'\
        'starts': [],
        'code-line': 'from engine import train_one_epoch, evaluate\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 12L,
        'sel-line-start': 372L,
        'selection_end': 383L,
        'selection_start': 377L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest/lib/python3.7/site-packages/_pytest/config/__init__.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest/lib/python3.7/site-packages/_pytest/python.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.7/site-packages/_pytest/python.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/python.py'): {'a'\
        'ttrib-starts': [('Module|0|',
                          495),
                         ('Module|0|._importtestmodule|0|',
                          573)],
        'code-line': '            raise self.CollectError(\n',
        'first-line': 574L,
        'folded-linenos': [],
        'sel-line': 579L,
        'sel-line-start': 21730L,
        'selection_end': 21730L,
        'selection_start': 21730L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/generic.py'): {'a'\
        'ttrib-starts': [('NDFrame|0|',
                          144),
                         ('NDFrame|0|.xs|0|',
                          3603)],
        'code-line': '            loc = index.get_loc(key)\n',
        'first-line': 3714L,
        'folded-linenos': [],
        'sel-line': 3735L,
        'sel-line-start': 125244L,
        'selection_end': 125244L,
        'selection_start': 125244L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/indexing.py'): {'a'\
        'ttrib-starts': [('_LocationIndexer|0|',
                          596),
                         ('_LocationIndexer|0|.__getitem__|0|',
                          880)],
        'code-line': '            return self._getitem_tuple(key)\n',
        'first-line': 882L,
        'folded-linenos': [],
        'sel-line': 887L,
        'sel-line-start': 27993L,
        'selection_end': 27993L,
        'selection_start': 27993L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/tifffile/tifffile.py'): {'a'\
        'ttrib-starts': [('TiffPage|0|',
                          5228),
                         ('TiffPage|0|.decode|0|',
                          5577),
                         ('TiffPage|0|.decode|0|.decode|1|',
                          5925)],
        'code-line': "                raise ValueError(f'TiffPage {self.inde"\
                     "x}: {exc}')\r\n",
        'first-line': 5612L,
        'folded-linenos': [],
        'sel-line': 5633L,
        'sel-line-start': 217235L,
        'selection_end': 217235L,
        'selection_start': 217235L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py'): {'a'\
        'ttrib-starts': [('Conv2d|0|',
                          261),
                         ('Conv2d|0|._conv_forward|0|',
                          413)],
        'code-line': '        return F.conv2d(input, weight, self.bias, self'\
                     '.stride,\n',
        'first-line': 395L,
        'folded-linenos': [],
        'sel-line': 418L,
        'sel-line-start': 18107L,
        'selection_end': 18107L,
        'selection_start': 18107L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py'): {'a'\
        'ttrib-starts': [('Module|0|',
                          177),
                         ('Module|0|._call_impl|0|',
                          714)],
        'code-line': '            result = self.forward(*input, **kwargs)\n',
        'first-line': 713L,
        'folded-linenos': [],
        'sel-line': 726L,
        'sel-line-start': 29761L,
        'selection_end': 29761L,
        'selection_start': 29761L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py'): {'a'\
        'ttrib-starts': [('default_collate|0|',
                          41)],
        'code-line': '        return {key: default_collate([d[key] for d in '\
                     'batch]) for key in elem}\n',
        'first-line': 52L,
        'folded-linenos': [],
        'sel-line': 72L,
        'sel-line-start': 2926L,
        'selection_end': 2926L,
        'selection_start': 2926L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py'): {'a'\
        'ttrib-starts': [('_BaseDatasetFetcher|0|',
                          6),
                         ('_BaseDatasetFetcher|0|.fetch|0|',
                          13)],
        'code-line': '        raise NotImplementedError()\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 14L,
        'sel-line-start': 511L,
        'selection_end': 546L,
        'selection_start': 546L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchsummary/torchsummary.py'): {'a'\
        'ttrib-starts': [('summary|0|',
                          8),
                         ('summary|0|.register_hook|0|',
                          10),
                         ('summary|0|.register_hook|0|.hook|0|',
                          12)],
        'code-line': '            summary[m_key]["input_shape"] = list(input'\
                     '[0].size())\n',
        'first-line': 9L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 482L,
        'selection_end': 482L,
        'selection_start': 482L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/transform.py'): {'a'\
        'ttrib-starts': [('GeneralizedRCNNTransform|0|',
                          57),
                         ('GeneralizedRCNNTransform|0|.forward|0|',
                          78)],
        'code-line': '                raise ValueError("images is expected t'\
                     'o be a list of 3d tensors "\n',
        'first-line': 87L,
        'folded-linenos': [],
        'sel-line': 101L,
        'sel-line-start': 3859L,
        'selection_end': 3859L,
        'selection_start': 3859L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py'): {'a'\
        'ttrib-starts': [('Resize|0|',
                          231),
                         ('Resize|0|.__init__|0|',
                          249)],
        'code-line': '            raise ValueError("If size is a sequence, i'\
                     't should have 1 or 2 values")\n',
        'first-line': 233L,
        'folded-linenos': [],
        'sel-line': 254L,
        'sel-line-start': 9069L,
        'selection_end': 9152L,
        'selection_start': 9069L,
        'zoom': 0L}}
proj.build-cmd = {None: ('default',
                         None)}
proj.env-vars = {None: ('default',
                        [u''])}
proj.initial-dir = {None: ('custom',
                           u'/Users/benweinstein/Documents/DeepForest-pytorch')}
proj.pyexec = {None: ('custom',
                      u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/bin/python3')}
proj.pypath = {None: ('custom',
                      [])}
proj.vcs-system-config = ('prefs',
                          {'bzr': {'versioncontrol.bzr.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.bzr.executable': u'bzr'},
                           'cvs': {'versioncontrol.cvs.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.cvs.executable': u'cvs',
                                   'versioncontrol.cvs.extra-global-args': '-'\
        'z3'},
                           'git': {'versioncontrol.git.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.git.executable': u'git',
                                   'versioncontrol.git.use-porcelain': True},
                           'hg': {'versioncontrol.hg.active': 'active-if-pro'\
        'ject-dir',
                                  'versioncontrol.hg.dont-find-unregistered': True,
                                  'versioncontrol.hg.executable': u'hg',
                                  'versioncontrol.hg.extra-global-args': '--'\
        'encoding=utf8'},
                           'perforce': {'versioncontrol.perforce.active': 'n'\
        'ot-active',
        'versioncontrol.perforce.dont-find-unregistered': True,
        'versioncontrol.perforce.executable': u'p4',
        'versioncontrol.perforce.extra-global-args': ''},
                           'svn': {'versioncontrol.svn.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.svn.executable': u'svn',
                                   'versioncontrol.svn.extra-global-args': '',
                                   'versioncontrol.svn.svnadmin-executable': u'svnadmin'}})
search.search-history = [u'sys',
                         u'nn.',
                         u'VideoMetaData',
                         u'torch',
                         u'random',
                         u'OrderedDict',
                         u'Tensor',
                         u'torch.',
                         u'overwrite_eps',
                         u'AnchorGenerator',
                         u'zipfile',
                         u'os',
                         u'glob',
                         u'errno',
                         u'_read_video_timestamps_from_file',
                         u'Union',
                         u'check_integrity',
                         u'get_iou',
                         u'engine',
                         u'get_data']
testing.stored-results = (1,
                          [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_environment.py',
                            [('test_environment',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              3)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                            [('test_predict_image_empty',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo TypeError(\"'tuple' object ca"\
                               "nnot be interpreted as an integer\") tblen=4"\
                               ">",
                               "TypeError: 'tuple' object cannot be interpre"\
                               "ted as an integer",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 42,
                                 'test_predict_image_empty',
                                 None,
                                 '    image = np.random.rand((400,400,3))'),
                                (u'/mtrand.pyx',
                                 'mtrand.pyx',
                                 1169,
                                 'numpy.random.mtrand.RandomState.rand',
                                 None,
                                 None),
                                (u'/mtrand.pyx',
                                 'mtrand.pyx',
                                 423,
                                 'numpy.random.mtrand.RandomState.random_sam'\
                                 'ple',
                                 None,
                                 None),
                                (u'/_common.pyx',
                                 '_common.pyx',
                                 270,
                                 'numpy.random._common.double_fill',
                                 None,
                                 None)],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1610046162,
                              40),
                             ('test_predict_tile',
                              0,
                              None,
                              None,
                              None,
                              1610045200,
                              64),
                             ('test_main',
                              0,
                              None,
                              None,
                              None,
                              1610045200,
                              34),
                             ('test_predict_file',
                              0,
                              None,
                              None,
                              None,
                              1610045200,
                              61),
                             ('test_predict_image_fromarray',
                              0,
                              None,
                              None,
                              None,
                              1610045896,
                              52),
                             ('test_train',
                              0,
                              None,
                              None,
                              None,
                              1610045200,
                              37),
                             ('test_predict_image_fromfile',
                              0,
                              None,
                              None,
                              None,
                              1610045361,
                              46)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_model.py',
                            [('test_load_backbone',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              5)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_preprocess.py',
                            [('test_select_annotations_tile',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              59),
                             ('test_select_annotations',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              44),
                             ('test_split_raster_empty',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              86),
                             ('test_compute_windows',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              38),
                             ('test_split_size_error',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              126),
                             ('test_split_raster',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              75)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_data.py',
                            [('test_get_data',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              7)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_utilities.py',
                            [('test_float_warning',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              33),
                             ('test_xml_to_annotations',
                              0,
                              None,
                              None,
                              None,
                              1609960817,
                              18)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_dataset.py',
                            [('test_TreeDataset',
                              0,
                              None,
                              None,
                              None,
                              1609978889,
                              7),
                             ('test_TreeDataset_transform[False]',
                              0,
                              None,
                              None,
                              None,
                              1609978889,
                              23),
                             ('test_TreeDataset_transform[True]',
                              0,
                              None,
                              None,
                              None,
                              1609978889,
                              23)])],
                          {u'/Users/benweinstein/Documents/DeepForest/tests/test_deepforest.py': (u'Test process aborted: some tests were not run',
        1607966490)})
